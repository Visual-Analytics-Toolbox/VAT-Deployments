kube-prometheus-stack:
  # all values are in https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
  crds:
    enabled: true

  grafana:
    # we use upstream grafana helm chart, not the one from kube-prometheus-stack
    enabled: false

  kubeProxy:
    enabled: false
  
  prometheusOperator:
    affinity: {}

  prometheus:
    enabled: true

    service:
      enabled: true
      targetPort: 9090

    ingress:
      enabled: true
      ingressClassName: "nginx"
      annotations:
        nginx.ingress.kubernetes.io/auth-signin: https://oauth2-proxy.berlin-united.com/oauth2/start?rd=https://$host$request_uri
        nginx.ingress.kubernetes.io/auth-url: http://oauth-proxy-oauth2-proxy.oauth-proxy.svc.cluster.local/oauth2/auth
        nginx.ingress.kubernetes.io/proxy-buffer-size: "64k"
        nginx.ingress.kubernetes.io/auth-response-headers: Authorization
      hosts:
      - "prometheus.berlin-united.com"
      tls:
        - secretName: tls-cert-prometheus
          hosts:
            - "prometheus.berlin-united.com"
    prometheusSpec:
      podMonitorSelectorNilUsesHelmValues: false
      podMonitorSelector: {}

      additionalScrapeConfigs:
        - job_name: 'kubernetes-pods'
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              action: keep
              regex: true
            - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
              action: replace
              regex: ([^:]+)(?::\d+)?;(\d+)
              replacement: ${1}:${2}
              target_label: __address__
loki:
  loki:
    auth_enabled: false
    commonConfig:
      replication_factor: 1
    schemaConfig:
      configs:
        - from: 2024-04-01
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h
    ingester:
      chunk_encoding: snappy
    tracing:
      enabled: true
    querier:
      # Default is 4, if you have enough memory and CPU you can increase, reduce if OOMing
      max_concurrent: 2
  deploymentMode: SingleBinary
  singleBinary:
    replicas: 1
    resources:
      limits:
        cpu: 3
        memory: 4Gi
      requests:
        cpu: 2
        memory: 2Gi
    extraEnv:
      # Keep a little bit lower than memory limits
      - name: GOMEMLIMIT
        value: 3750MiB

  chunksCache:
    # default is 500MB, with limited memory keep this smaller
    writebackSizeLimit: 10MB

  # Enable minio for storage
  minio:
    enabled: true

  # Zero out replica counts of other deployment modes
  backend:
    replicas: 0
  read:
    replicas: 0
  write:
    replicas: 0

  ingester:
    replicas: 0
  querier:
    replicas: 0
  queryFrontend:
    replicas: 0
  queryScheduler:
    replicas: 0
  distributor:
    replicas: 0
  compactor:
    replicas: 0
  indexGateway:
    replicas: 0
  bloomCompactor:
    replicas: 0
  bloomGateway:
    replicas: 0


